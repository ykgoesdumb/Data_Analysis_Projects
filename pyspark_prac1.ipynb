{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyspark 연습 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyspark 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 281.4 MB 39 kB/s s eta 0:00:01  |▍                               | 3.8 MB 7.3 MB/s eta 0:00:38     |▌                               | 4.3 MB 7.3 MB/s eta 0:00:38     |▌                               | 4.8 MB 7.3 MB/s eta 0:00:38     |█                               | 8.7 MB 7.3 MB/s eta 0:00:38[K     |█                               | 9.7 MB 7.3 MB/s eta 0:00:38     |██▉                             | 24.6 MB 7.8 MB/s eta 0:00:33     |████████▊                       | 76.7 MB 12.2 MB/s eta 0:00:17     |██████████████▌                 | 127.8 MB 2.3 MB/s eta 0:01:0708     |█████████████████████████▌      | 224.1 MB 8.8 MB/s eta 0:00:07     |███████████████████████████▋    | 242.6 MB 12.2 MB/s eta 0:00:04\n",
      "\u001b[?25hCollecting py4j==0.10.9.3\n",
      "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=8d7893e23b998fd2f7e423296b371e6ce131f02e71e484a2b68794b5455df90f\n",
      "  Stored in directory: /Users/mijeongkim/Library/Caches/pip/wheels/52/45/50/69db7b6e1da74a1b9fcc097827db9185cb8627117de852731e\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyspark 연습하기\n",
    "\n",
    "\n",
    "데이터셋은 붓꽃 데이터로 해보았다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pyspark\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 붓꽃데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data = iris_data, columns = iris.feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.to_csv('test1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장먼저 해야 될 것은 Sparksession 만들기이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/21 14:39:07 WARN Utils: Your hostname, miui-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.10.232 instead (on interface en0)\n",
      "22/04/21 14:39:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/21 14:39:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/04/21 14:39:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName('Practice')\\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.10.232:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f7f1df5aa60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark 로 데이터셋을 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+----------------+-----------------+----------------+\n",
      "| _c0|              _c1|             _c2|              _c3|             _c4|\n",
      "+----+-----------------+----------------+-----------------+----------------+\n",
      "|null|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|\n",
      "|   0|              5.1|             3.5|              1.4|             0.2|\n",
      "|   1|              4.9|             3.0|              1.4|             0.2|\n",
      "|   2|              4.7|             3.2|              1.3|             0.2|\n",
      "|   3|              4.6|             3.1|              1.5|             0.2|\n",
      "|   4|              5.0|             3.6|              1.4|             0.2|\n",
      "|   5|              5.4|             3.9|              1.7|             0.4|\n",
      "|   6|              4.6|             3.4|              1.4|             0.3|\n",
      "|   7|              5.0|             3.4|              1.5|             0.2|\n",
      "|   8|              4.4|             2.9|              1.4|             0.2|\n",
      "|   9|              4.9|             3.1|              1.5|             0.1|\n",
      "|  10|              5.4|             3.7|              1.5|             0.2|\n",
      "|  11|              4.8|             3.4|              1.6|             0.2|\n",
      "|  12|              4.8|             3.0|              1.4|             0.1|\n",
      "|  13|              4.3|             3.0|              1.1|             0.1|\n",
      "|  14|              5.8|             4.0|              1.2|             0.2|\n",
      "|  15|              5.7|             4.4|              1.5|             0.4|\n",
      "|  16|              5.4|             3.9|              1.3|             0.4|\n",
      "|  17|              5.1|             3.5|              1.4|             0.3|\n",
      "|  18|              5.7|             3.8|              1.7|             0.3|\n",
      "+----+-----------------+----------------+-----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Header를  True 로 설정해서 깔끔하게 read 하는 방법도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+----------------+-----------------+----------------+\n",
      "|_c0|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|\n",
      "+---+-----------------+----------------+-----------------+----------------+\n",
      "|  0|              5.1|             3.5|              1.4|             0.2|\n",
      "|  1|              4.9|             3.0|              1.4|             0.2|\n",
      "|  2|              4.7|             3.2|              1.3|             0.2|\n",
      "|  3|              4.6|             3.1|              1.5|             0.2|\n",
      "|  4|              5.0|             3.6|              1.4|             0.2|\n",
      "|  5|              5.4|             3.9|              1.7|             0.4|\n",
      "|  6|              4.6|             3.4|              1.4|             0.3|\n",
      "|  7|              5.0|             3.4|              1.5|             0.2|\n",
      "|  8|              4.4|             2.9|              1.4|             0.2|\n",
      "|  9|              4.9|             3.1|              1.5|             0.1|\n",
      "| 10|              5.4|             3.7|              1.5|             0.2|\n",
      "| 11|              4.8|             3.4|              1.6|             0.2|\n",
      "| 12|              4.8|             3.0|              1.4|             0.1|\n",
      "| 13|              4.3|             3.0|              1.1|             0.1|\n",
      "| 14|              5.8|             4.0|              1.2|             0.2|\n",
      "| 15|              5.7|             4.4|              1.5|             0.4|\n",
      "| 16|              5.4|             3.9|              1.3|             0.4|\n",
      "| 17|              5.1|             3.5|              1.4|             0.3|\n",
      "| 18|              5.7|             3.8|              1.7|             0.3|\n",
      "| 19|              5.1|             3.8|              1.5|             0.3|\n",
      "+---+-----------------+----------------+-----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/21 15:22:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , sepal length (cm), sepal width (cm), petal length (cm), petal width (cm)\n",
      " Schema: _c0, sepal length (cm), sepal width (cm), petal length (cm), petal width (cm)\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/mijeongkim/git/test1.csv\n"
     ]
    }
   ],
   "source": [
    "spark.read.options(header = 'True',\\\n",
    "                inferschema = 'True',\\\n",
    "                delimiter = ',').csv('test1.csv').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.options(\n",
    "                header = 'True',\n",
    "                inferschema = 'True',\n",
    "                delimiter = ',').csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/21 15:25:21 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , sepal length (cm), sepal width (cm), petal length (cm), petal width (cm)\n",
      " Schema: _c0, sepal length (cm), sepal width (cm), petal length (cm), petal width (cm)\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/mijeongkim/git/test1.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(_c0=0, sepal length (cm)=5.1, sepal width (cm)=3.5, petal length (cm)=1.4, petal width (cm)=0.2),\n",
       " Row(_c0=1, sepal length (cm)=4.9, sepal width (cm)=3.0, petal length (cm)=1.4, petal width (cm)=0.2),\n",
       " Row(_c0=2, sepal length (cm)=4.7, sepal width (cm)=3.2, petal length (cm)=1.3, petal width (cm)=0.2),\n",
       " Row(_c0=3, sepal length (cm)=4.6, sepal width (cm)=3.1, petal length (cm)=1.5, petal width (cm)=0.2),\n",
       " Row(_c0=4, sepal length (cm)=5.0, sepal width (cm)=3.6, petal length (cm)=1.4, petal width (cm)=0.2),\n",
       " Row(_c0=5, sepal length (cm)=5.4, sepal width (cm)=3.9, petal length (cm)=1.7, petal width (cm)=0.4),\n",
       " Row(_c0=6, sepal length (cm)=4.6, sepal width (cm)=3.4, petal length (cm)=1.4, petal width (cm)=0.3),\n",
       " Row(_c0=7, sepal length (cm)=5.0, sepal width (cm)=3.4, petal length (cm)=1.5, petal width (cm)=0.2),\n",
       " Row(_c0=8, sepal length (cm)=4.4, sepal width (cm)=2.9, petal length (cm)=1.4, petal width (cm)=0.2),\n",
       " Row(_c0=9, sepal length (cm)=4.9, sepal width (cm)=3.1, petal length (cm)=1.5, petal width (cm)=0.1)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PrintSchema\n",
    "\n",
    "pandas 의 df.info() 와 비슷하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- sepal length (cm): double (nullable = true)\n",
      " |-- sepal width (cm): double (nullable = true)\n",
      " |-- petal length (cm): double (nullable = true)\n",
      " |-- petal width (cm): double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a04e1936a8279292722c1dee4730d7414b74ec89bd57cee0a3482b9ac557871b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
